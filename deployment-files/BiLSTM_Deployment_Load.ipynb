{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.9.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.4 64-bit"
    },
    "interpreter": {
      "hash": "5eb756464d92b1fba7c316c219a9aedd64e50b1f9cf7b2745bd052621490d6a2"
    },
    "colab": {
      "name": "BiLSTM_Deployment_Load.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install azureml library"
      ],
      "metadata": {
        "id": "TTg8xWWuUtDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "! pip install azureml-core"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq157FQgnayO",
        "outputId": "a7e1a20c-4854-494a-c010-9a8b072eb332"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create workspace from Azure Machine Learning workspace"
      ],
      "metadata": {
        "id": "SP5cQLx9Uop7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "source_dir = \"./source_dir/\"\r\n",
        "\r\n",
        "ws = Workspace.from_config(path = source_dir + \"config.json\")\r\n",
        "print(ws)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-kDETxkozhl",
        "outputId": "7fede9bc-551a-4c80-aadc-9c3751d0be1e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "gxaZ8qR852wE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "import os\r\n",
        "import json\r\n",
        "\r\n",
        "import tensorflow as tf"
      ],
      "outputs": [],
      "metadata": {
        "id": "F5sNNa3D52wF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load tokenizer from saved tokenizer"
      ],
      "metadata": {
        "id": "LYWP1iOQ52wF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "with open(os.path.join(source_dir, 'models/Commonlit-Bi-LSTM/assets/tokenizer.json')) as f:\r\n",
        "    data = json.load(f)\r\n",
        "    tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(data)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mtp9ktSs52wG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the maximum sequence length from all the Commonlit provided excerpts stored in txt file"
      ],
      "metadata": {
        "id": "mNgb1kP352wH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "with open(source_dir + 'models/Commonlit-Bi-LSTM/assets/max_length.txt', 'r') as text:\r\n",
        "    max_length = int(text.read())"
      ],
      "outputs": [],
      "metadata": {
        "id": "d7mxLG0C52wI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test loading of pre-trained model"
      ],
      "metadata": {
        "id": "-WHHo-0TUiQU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "model_load = tf.keras.models.load_model(source_dir + 'models/Commonlit-Bi-LSTM')\r\n",
        "model_load.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 215, 90)           2581650   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 256)               224256    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 2,806,163\n",
            "Trainable params: 2,806,163\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUtLmcMWZhru",
        "outputId": "2475647b-be31-4fb2-c88c-e56e34f35411"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register saved model on Azure"
      ],
      "metadata": {
        "id": "7miGRWMuS1yD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "# Register model\r\n",
        "model = Model.register(workspace = ws, \r\n",
        "                       model_name = \"Commonlit-Bi-LSTM\",\r\n",
        "                       model_path = source_dir + \"models/Commonlit-Bi-LSTM\",\r\n",
        "                       model_framework = \"TensorFlow\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering model Commonlit-BiLSTM\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsvHpWvazEGE",
        "outputId": "ca1c7947-6edb-4c87-d0c6-2dd1494a054e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create environment with necessary dependencies"
      ],
      "metadata": {
        "id": "k8tvXAI7S8x4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "\r\n",
        "env = Environment(name = \"Commonlit-Bi-LSTM\")\r\n",
        "conda_dep = CondaDependencies()\r\n",
        "conda_dep.add_conda_package(\"numpy\")\r\n",
        "conda_dep.add_pip_package(\"keras\")\r\n",
        "\r\n",
        "conda_dep.add_pip_package('tensorflow==2.6.0')\r\n",
        "\r\n",
        "conda_dep.add_pip_package(\"azureml-defaults\")\r\n",
        "conda_dep.add_pip_package(\"azureml\")\r\n",
        "conda_dep.add_pip_package(\"azureml-contrib-functions\")\r\n",
        "\r\n",
        "env.python.conda_dependencies = conda_dep"
      ],
      "outputs": [],
      "metadata": {
        "id": "HLtc2V-Z0xpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create inference configuration using scoring function"
      ],
      "metadata": {
        "id": "-Bd1dvM7TAta"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "inference_config = InferenceConfig(\r\n",
        "    environment = env,\r\n",
        "    source_directory = \"./source_dir\",\r\n",
        "    entry_script = \"./Bi-LSTM_score_LOAD.py\",\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "ndAkCFrC1bxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Azure Container Instance and deploy model to container"
      ],
      "metadata": {
        "id": "jeqyOZoSTGjh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "from azureml.core.webservice import AciWebservice\r\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores = 2, memory_gb = 2)\r\n",
        "service = Model.deploy(\r\n",
        "    ws,\r\n",
        "    \"commonlit-bi-lstm\",\r\n",
        "    [model],\r\n",
        "    inference_config,\r\n",
        "    aci_config,\r\n",
        "    overwrite = True,\r\n",
        ")\r\n",
        "service.wait_for_deployment(show_output = True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2021-08-27 23:29:15+00:00 Creating Container Registry if not exists.\n",
            "2021-08-27 23:29:16+00:00 Registering the environment.\n",
            "2021-08-27 23:29:20+00:00 Use the existing image.\n",
            "2021-08-27 23:29:20+00:00 Generating deployment configuration.\n",
            "2021-08-27 23:29:21+00:00 Submitting deployment to compute..\n",
            "2021-08-27 23:29:28+00:00 Checking the status of deployment commonlit-bi-lstm..\n",
            "2021-08-27 23:49:53+00:00 Checking the status of inference endpoint commonlit-bi-lstm.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK7dPjJr2YT_",
        "outputId": "ed253b7d-b3ac-44e1-de11-0eb7520bb675"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Endpoint Consumption - Test 1"
      ],
      "metadata": {
        "id": "panzXiIKTMz0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "import requests\r\n",
        "import json\r\n",
        "\r\n",
        "uri = service.scoring_uri\r\n",
        "requests.get(\"\")\r\n",
        "headers = {\"Content-Type\": \"application/json\"}\r\n",
        "data = {\r\n",
        "    'data': ['Cell division is the process by which a parent cell divides into two or more daughter cells. Cell division usually occurs as part of a larger cell cycle.\\n In eukaryotes, there are two distinct types of cell division: a vegetative division, whereby each daughter cell is genetically identical to the parent cell (mitosis), and a reproductive cell division, whereby the number of chromosomes in the daughter cells is reduced by half, to produce haploid gametes (meiosis). \\nMeiosis results in four haploid daughter cells by undergoing one round of DNA replication followed by two divisions: homologous chromosomes are separated in the first division, and sister chromatids are separated in the second division.\\nBoth of these cell division cycles are used in sexually reproducing organisms at some point in their life cycle, and both are believed to be present in the last eukaryotic common ancestor. Prokaryotes also undergo a vegetative cell division known as binary fission, where their genetic material is segregated equally into two daughter cells. All cell divisions, regardless of organism, are preceded by a single round of DNA replication.']\r\n",
        "}\r\n",
        "data = json.dumps(data)\r\n",
        "response = requests.post(uri, data = data, headers = headers)\r\n",
        "print(response.json())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.2895405292510986]\n"
          ]
        }
      ],
      "metadata": {
        "id": "iquzod856XeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6d8aec4-14ca-4e5d-c499-9746c6a1d5d7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Endpoint Consumption - Test 2"
      ],
      "metadata": {
        "id": "UN-EdJ4DTQdF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "import urllib.request\r\n",
        "import json\r\n",
        "import os\r\n",
        "import ssl\r\n",
        "\r\n",
        "def allowSelfSignedHttps(allowed):\r\n",
        "    # bypass the server certificate verification on client side\r\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\r\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\r\n",
        "\r\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\r\n",
        "\r\n",
        "# Request data goes here\r\n",
        "data = {\r\n",
        "    'data': ['Dotty continued to go to Mrs. Gray\\'s every night with the milk. Sometimes Katie went with her, and then they always paused a while under the acorn-tree and played \"King and Queen.\" Dotty said she wished they could ever remember to bring their nipperkins, for in that case the milk would taste a great deal more like nectar. The \"nipperkins\" were a pair of handled cups which the children supposed to be silver, and which they always used at table.\\nDotty knew she was doing wrong every time she played \"King and Queen.\" She knew the milk was not hers, but Mrs. Gray\\'s; still she said to herself, \"Ruthie needn\\'t give so much measure, all pressed down and run over. If Queenie and I should drink a great deal more, there would always be a quart left. Yes, I know there would.\"\\nMrs. Gray never said anything about the milk; she merely poured it out in a pan, and gave back the pail to Dotty, asking her at the same time as many questions as the child would stay to hear.',\r\n",
        "             'Cell division is the process by which a parent cell divides into two or more daughter cells. Cell division usually occurs as part of a larger cell cycle.\\n In eukaryotes, there are two distinct types of cell division: a vegetative division, whereby each daughter cell is genetically identical to the parent cell (mitosis), and a reproductive cell division, whereby the number of chromosomes in the daughter cells is reduced by half, to produce haploid gametes (meiosis). \\nMeiosis results in four haploid daughter cells by undergoing one round of DNA replication followed by two divisions: homologous chromosomes are separated in the first division, and sister chromatids are separated in the second division.\\nBoth of these cell division cycles are used in sexually reproducing organisms at some point in their life cycle, and both are believed to be present in the last eukaryotic common ancestor. Prokaryotes also undergo a vegetative cell division known as binary fission, where their genetic material is segregated equally into two daughter cells. All cell divisions, regardless of organism, are preceded by a single round of DNA replication.'],\r\n",
        "}\r\n",
        "\r\n",
        "body = str.encode(json.dumps(data))\r\n",
        "\r\n",
        "url = ''\r\n",
        "api_key = '' # Replace this with the API key for the web service\r\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\r\n",
        "\r\n",
        "req = urllib.request.Request(url, body, headers)\r\n",
        "\r\n",
        "try:\r\n",
        "    response = urllib.request.urlopen(req)\r\n",
        "\r\n",
        "    result = response.read()\r\n",
        "    print(result)\r\n",
        "except urllib.error.HTTPError as error:\r\n",
        "    print(\"The request failed with status code: \" + str(error.code))\r\n",
        "\r\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\r\n",
        "    print(error.info())\r\n",
        "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'[-0.22421894967556, -2.2895405292510986]'\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49E2NJ_W83wR",
        "outputId": "99971725-52a8-4393-b5d2-f3915c77ea90"
      }
    }
  ]
}