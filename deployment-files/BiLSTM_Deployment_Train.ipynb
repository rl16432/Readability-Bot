{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "CommonlitBidirectionalLSTM - Seed 3 Deployment ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.4 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "5eb756464d92b1fba7c316c219a9aedd64e50b1f9cf7b2745bd052621490d6a2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install azureml library"
      ],
      "metadata": {
        "id": "TTg8xWWuUtDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "! pip install azureml-core"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azureml-core\n",
            "  Downloading azureml_core-1.33.0.post1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting PyJWT<3.0.0\n",
            "  Downloading PyJWT-2.1.0-py3-none-any.whl (16 kB)\n",
            "Collecting ruamel.yaml<0.17.5,>=0.15.35\n",
            "  Downloading ruamel.yaml-0.17.4-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 9.5 MB/s \n",
            "\u001b[?25hCollecting msrest<1.0.0,>=0.5.1\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting SecretStorage<4.0.0\n",
            "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contextlib2<1.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core) (0.5.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from azureml-core) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.19.1 in /usr/local/lib/python3.7/dist-packages (from azureml-core) (2.23.0)\n",
            "Collecting ndg-httpsclient<=0.5.1\n",
            "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
            "Collecting pathspec<1.0.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting backports.tempfile\n",
            "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
            "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
            "\u001b[K     |████████████████████████████████| 547 kB 45.9 MB/s \n",
            "\u001b[?25hCollecting msrestazure<=0.6.4,>=0.4.33\n",
            "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting jsonpickle<3.0.0\n",
            "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting docker<5.0.0\n",
            "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 51.5 MB/s \n",
            "\u001b[?25hCollecting pyopenssl<21.0.0\n",
            "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting azure-mgmt-keyvault<10.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_keyvault-9.0.0-py2.py3-none-any.whl (312 kB)\n",
            "\u001b[K     |████████████████████████████████| 312 kB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<=1.26.5,>=1.23 in /usr/local/lib/python3.7/dist-packages (from azureml-core) (1.24.3)\n",
            "Collecting azure-mgmt-containerregistry>=2.0.0\n",
            "  Downloading azure_mgmt_containerregistry-8.1.0-py2.py3-none-any.whl (796 kB)\n",
            "\u001b[K     |████████████████████████████████| 796 kB 46.7 MB/s \n",
            "\u001b[?25hCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n",
            "  Downloading cryptography-3.4.8-cp36-abi3-manylinux_2_24_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 22.8 MB/s \n",
            "\u001b[?25hCollecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
            "  Downloading azure_mgmt_resource-13.0.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 31.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from azureml-core) (2.8.2)\n",
            "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting azure-common<2.0.0,>=1.1.12\n",
            "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
            "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
            "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 46.5 MB/s \n",
            "\u001b[?25hCollecting adal<=1.2.7,>=1.2.0\n",
            "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting azure-mgmt-core<2.0.0,>=1.2.0\n",
            "  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\n",
            "Collecting azure-core<2.0.0,>=1.15.0\n",
            "  Downloading azure_core-1.17.0-py2.py3-none-any.whl (165 kB)\n",
            "\u001b[K     |████████████████████████████████| 165 kB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from azure-core<2.0.0,>=1.15.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-mgmt-containerregistry>=2.0.0->azureml-core) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0->azureml-core) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0->azureml-core) (2.20)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonpickle<3.0.0->azureml-core) (4.6.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest<1.0.0,>=0.5.1->azureml-core) (1.3.0)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from msrest<1.0.0,>=0.5.1->azureml-core) (2021.5.30)\n",
            "Requirement already satisfied: pyasn1>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from ndg-httpsclient<=0.5.1->azureml-core) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.19.1->azureml-core) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.19.1->azureml-core) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest<1.0.0,>=0.5.1->azureml-core) (3.1.1)\n",
            "Collecting ruamel.yaml.clib>=0.1.2\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting jeepney>=0.6\n",
            "  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting backports.weakref\n",
            "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonpickle<3.0.0->azureml-core) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonpickle<3.0.0->azureml-core) (3.5.0)\n",
            "Installing collected packages: PyJWT, isodate, cryptography, msrest, azure-core, adal, websocket-client, ruamel.yaml.clib, pyopenssl, msrestazure, jeepney, backports.weakref, azure-mgmt-core, azure-common, SecretStorage, ruamel.yaml, pathspec, ndg-httpsclient, jsonpickle, jmespath, docker, backports.tempfile, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, azureml-core\n",
            "Successfully installed PyJWT-2.1.0 SecretStorage-3.3.1 adal-1.2.7 azure-common-1.1.27 azure-core-1.17.0 azure-graphrbac-0.61.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-8.1.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.0.0 azure-mgmt-resource-13.0.0 azure-mgmt-storage-11.2.0 azureml-core-1.33.0.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cryptography-3.4.8 docker-4.4.4 isodate-0.6.0 jeepney-0.7.1 jmespath-0.10.0 jsonpickle-2.0.0 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 pathspec-0.9.0 pyopenssl-20.0.1 ruamel.yaml-0.17.4 ruamel.yaml.clib-0.2.6 websocket-client-1.2.1\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq157FQgnayO",
        "outputId": "aa9a14ba-afcc-4a74-d45c-f53b3ad2bd58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create workspace from Azure Machine Learning workspace"
      ],
      "metadata": {
        "id": "SP5cQLx9Uop7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "source_dir = \"./source_dir/\"\r\n",
        "\r\n",
        "ws = Workspace.from_config(path = source_dir + \"config.json\")\r\n",
        "print(ws)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing interactive authentication. Please follow the instructions on the terminal.\n",
            "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code EBFWUVXC8 to authenticate.\n",
            "You have logged in. Now let us find all the subscriptions to which you have access...\n",
            "Interactive authentication successfully completed.\n",
            "Workspace.create(name='Test-Deployment-Space', subscription_id='9d7c60f0-d3e1-49c3-b70b-080e861838c1', resource_group='Test-Deployment')\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-kDETxkozhl",
        "outputId": "c629a54d-e0e8-4ab7-e535-b4d9a478658c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Re-training LSTM model from Kaggle with same seed"
      ],
      "metadata": {
        "id": "XFkX6QZfUV6I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "import numpy as np # linear algebra\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "import random\r\n",
        "import os\r\n",
        "import io\r\n",
        "import json\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "metadata": {
        "id": "4jWYKx5vqI_O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "tf.random.set_seed(3)\r\n",
        "np.random.seed(3)\r\n",
        "random.seed(3)\r\n",
        "os.environ['PYTHONHASHSEED'] = '3'"
      ],
      "outputs": [],
      "metadata": {
        "id": "P2C9oZoNr4Xj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "source_dir = \"./source_dir/\"\r\n",
        "train_eval_data = pd.read_csv(source_dir + \"input/train.csv\")\r\n",
        "pred_data = pd.read_csv(source_dir + \"input/test.csv\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "vCC1vnqLvKNW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "train_data, eval_data = train_test_split(train_eval_data, test_size = 0.2, random_state = 42)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4i550skmwndy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "train_text = train_data.loc[:,'excerpt'].values\r\n",
        "pred_text = pred_data.loc[:,'excerpt'].values\r\n",
        "eval_text = eval_data.loc[:,'excerpt'].values\r\n",
        "\r\n",
        "train_targets = train_data.loc[:,'target'].values\r\n",
        "eval_targets = eval_data.loc[:,'target'].values"
      ],
      "outputs": [],
      "metadata": {
        "id": "aOzUaDlbwqbi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer, text_to_word_sequence\r\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "tokenizer = Tokenizer()\r\n",
        "\r\n",
        "total_text = np.concatenate((train_text, eval_text, pred_text))\r\n",
        "All_text = np.array([text_to_word_sequence(s) for s in total_text], dtype = \"object\")\r\n",
        "\r\n",
        "tokenizer.fit_on_texts(All_text)\r\n",
        "\r\n",
        "max_length = max([len(s) for s in All_text])\r\n",
        "\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "\r\n",
        "train_text_tokens = tokenizer.texts_to_sequences(train_text)\r\n",
        "eval_text_tokens = tokenizer.texts_to_sequences(eval_text)\r\n",
        "pred_text_tokens = tokenizer.texts_to_sequences(pred_text)\r\n",
        "\r\n",
        "pad_train_tokens = pad_sequences(train_text_tokens, maxlen = max_length, padding = \"pre\")\r\n",
        "pad_eval_tokens = pad_sequences(eval_text_tokens, maxlen = max_length, padding = \"pre\")\r\n",
        "pad_pred_tokens = pad_sequences(pred_text_tokens, maxlen = max_length, padding = \"pre\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "V3s2SWuHw19v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import LSTM, Dense, Bidirectional\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.initializers import GlorotNormal\r\n",
        "from keras.losses import MeanSquaredError\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "EMBEDDING_SIZE = 90\r\n",
        "\r\n",
        "model.add(Embedding(vocab_size, EMBEDDING_SIZE, input_length = max_length, mask_zero = True,\r\n",
        "                    embeddings_initializer = GlorotNormal()))\r\n",
        "model.add(Bidirectional(LSTM(units = 128, dropout = 0.8)))\r\n",
        "model.add(Dense(activation=\"linear\", units = 1))\r\n",
        "\r\n",
        "model.compile(loss = MeanSquaredError(), optimizer = tf.keras.optimizers.Adam(\r\n",
        "              learning_rate=2e-4), metrics = ['mse'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "b-upXBOzw-x_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "model.fit(pad_train_tokens, train_targets, batch_size = 100, validation_data = (pad_eval_tokens, eval_targets), epochs = 10)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "23/23 [==============================] - ETA: 0s - loss: 1.8458 - mse: 1.8458"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-9-0065257b5012>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_train_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpad_eval_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1215\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1216\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    954\u001b[0m               *args, **kwds)\n\u001b[0;32m    955\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m       return self._concrete_stateful_fn._call_flat(\n\u001b[0m\u001b[0;32m    957\u001b[0m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "metadata": {
        "id": "2pBA-z1qxISz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5479c83b-6c2a-466b-f45d-903fd34921e2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save pre-trained model"
      ],
      "metadata": {
        "id": "H9tqbbFhUeJc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.save('./outputs/model1')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./outputs/model2/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./outputs/model2/assets\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTLI0Q_Ft6HG",
        "outputId": "1eb8edc6-8255-4e5f-d68b-19c908eb1a34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save fitted Tokenizer for this model as tokenizer.json"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "tokenizer_json = tokenizer.to_json()\r\n",
        "with io.open('./outputs/model1/assets/tokenizer.json', 'w', encoding='utf-8') as f:\r\n",
        "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save max_length attribute which determines the necessary padding"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "with open('./outputs/model1/assets/max_length.txt', 'w') as text:\r\n",
        "    text.write(str(max_length))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test loading of pre-trained model"
      ],
      "metadata": {
        "id": "-WHHo-0TUiQU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "model_load = tf.keras.models.load_model('./outputs/model1')\r\n",
        "model_load.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 215, 90)           2581650   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 256)               224256    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 2,806,163\n",
            "Trainable params: 2,806,163\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUtLmcMWZhru",
        "outputId": "ccaa2938-0d2d-4a96-8428-e61c3c2b197b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make predictions and store in np.ndarray"
      ],
      "metadata": {
        "id": "iMV5IWD5Sizm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "test_preds = model_load.predict(x = pad_pred_tokens)\r\n",
        "test_preds"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.2834516 ],\n",
              "       [-0.22421896],\n",
              "       [-0.595436  ],\n",
              "       [-2.2895405 ],\n",
              "       [-1.713674  ],\n",
              "       [-0.2228559 ],\n",
              "       [-0.02093622]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC_DN6nHa1m_",
        "outputId": "2aab887c-0cae-40c2-fa35-45d4060b1e69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert test_preds to list of labels of type 'float'"
      ],
      "metadata": {
        "id": "Z_DtrU5pSpLe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "test_preds_list = test_preds.flatten().tolist()\r\n",
        "test_preds_list"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-1.2834515571594238,\n",
              " -0.2242189645767212,\n",
              " -0.5954359769821167,\n",
              " -2.2895405292510986,\n",
              " -1.7136739492416382,\n",
              " -0.22285589575767517,\n",
              " -0.02093621902167797]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "metadata": {
        "id": "7__KUQ5OI5Fe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register saved model on Azure"
      ],
      "metadata": {
        "id": "7miGRWMuS1yD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "# Register model\r\n",
        "model = Model.register(workspace = ws, \r\n",
        "                       model_name = \"Commonlit-BiLSTM\",\r\n",
        "                       model_path = \"./outputs/model1\",\r\n",
        "                       model_framework = \"TensorFlow\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering model Commonlit-BiLSTM-Seed3\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsvHpWvazEGE",
        "outputId": "8329301d-e2de-4085-ea21-f7688f1db05d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create environment with necessary dependencies"
      ],
      "metadata": {
        "id": "k8tvXAI7S8x4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "\r\n",
        "env = Environment(name = \"Commonlit-BiLSTM\")\r\n",
        "conda_dep = CondaDependencies()\r\n",
        "conda_dep.add_conda_package(\"numpy\")\r\n",
        "conda_dep.add_pip_package(\"keras\")\r\n",
        "conda_dep.add_pip_package(\"pandas\")\r\n",
        "\r\n",
        "conda_dep.add_pip_package('tensorflow==2.6.0')\r\n",
        "conda_dep.add_pip_package('sklearn')\r\n",
        "\r\n",
        "conda_dep.add_pip_package(\"azureml-defaults\")\r\n",
        "conda_dep.add_pip_package(\"azureml\")\r\n",
        "conda_dep.add_pip_package(\"azureml-contrib-functions\")\r\n",
        "\r\n",
        "env.python.conda_dependencies = conda_dep"
      ],
      "outputs": [],
      "metadata": {
        "id": "HLtc2V-Z0xpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create inference configuration using scoring function"
      ],
      "metadata": {
        "id": "-Bd1dvM7TAta"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "inference_config = InferenceConfig(\r\n",
        "    environment = env,\r\n",
        "    source_directory = \"./source_dir\",\r\n",
        "    entry_script = \"./echo_score_TRAIN.py\",\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "ndAkCFrC1bxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Azure Container Instance and deploy model to container"
      ],
      "metadata": {
        "id": "jeqyOZoSTGjh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.webservice import AciWebservice\r\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores = 2, memory_gb = 2)\r\n",
        "service = Model.deploy(\r\n",
        "    ws,\r\n",
        "    \"commonlit-bi-lstm\",\r\n",
        "    [model],\r\n",
        "    inference_config,\r\n",
        "    aci_config,\r\n",
        "    overwrite = True,\r\n",
        ")\r\n",
        "service.wait_for_deployment(show_output = True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2021-08-27 02:00:02+00:00 Creating Container Registry if not exists.\n",
            "2021-08-27 02:00:02+00:00 Registering the environment.\n",
            "2021-08-27 02:00:05+00:00 Use the existing image.\n",
            "2021-08-27 02:00:05+00:00 Generating deployment configuration.\n",
            "2021-08-27 02:00:06+00:00 Submitting deployment to compute..\n",
            "2021-08-27 02:00:10+00:00 Checking the status of deployment commonlit-bilstm-seed3..\n",
            "2021-08-27 02:04:53+00:00 Checking the status of inference endpoint commonlit-bilstm-seed3.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK7dPjJr2YT_",
        "outputId": "5ed5394b-57be-436e-ceaa-55e94b85cea6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Endpoint Consumption - Test 1"
      ],
      "metadata": {
        "id": "panzXiIKTMz0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import requests\r\n",
        "import json\r\n",
        "\r\n",
        "uri = service.scoring_uri\r\n",
        "requests.get(\"http://16705546-cea5-4e3e-99a7-6274ca5c4289.australiaeast.azurecontainer.io/score\")\r\n",
        "headers = {\"Content-Type\": \"application/json\"}\r\n",
        "data = {\r\n",
        "    'data': ['Cell division is the process by which a parent cell divides into two or more daughter cells. Cell division usually occurs as part of a larger cell cycle.\\n In eukaryotes, there are two distinct types of cell division: a vegetative division, whereby each daughter cell is genetically identical to the parent cell (mitosis), and a reproductive cell division, whereby the number of chromosomes in the daughter cells is reduced by half, to produce haploid gametes (meiosis). \\nMeiosis results in four haploid daughter cells by undergoing one round of DNA replication followed by two divisions: homologous chromosomes are separated in the first division, and sister chromatids are separated in the second division.\\nBoth of these cell division cycles are used in sexually reproducing organisms at some point in their life cycle, and both are believed to be present in the last eukaryotic common ancestor. Prokaryotes also undergo a vegetative cell division known as binary fission, where their genetic material is segregated equally into two daughter cells. All cell divisions, regardless of organism, are preceded by a single round of DNA replication.']\r\n",
        "}\r\n",
        "data = json.dumps(data)\r\n",
        "response = requests.post(uri, data = data, headers = headers)\r\n",
        "print(response.json())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.2895405292510986]\n"
          ]
        }
      ],
      "metadata": {
        "id": "iquzod856XeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56d44777-01d3-4ab5-b592-e0757ffbd7fd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Endpoint Consumption - Test 2"
      ],
      "metadata": {
        "id": "UN-EdJ4DTQdF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import urllib.request\r\n",
        "import json\r\n",
        "import os\r\n",
        "import ssl\r\n",
        "\r\n",
        "def allowSelfSignedHttps(allowed):\r\n",
        "    # bypass the server certificate verification on client side\r\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\r\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\r\n",
        "\r\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\r\n",
        "\r\n",
        "# Request data goes here\r\n",
        "data = {\r\n",
        "    'data': ['Dotty continued to go to Mrs. Gray\\'s every night with the milk. Sometimes Katie went with her, and then they always paused a while under the acorn-tree and played \"King and Queen.\" Dotty said she wished they could ever remember to bring their nipperkins, for in that case the milk would taste a great deal more like nectar. The \"nipperkins\" were a pair of handled cups which the children supposed to be silver, and which they always used at table.\\nDotty knew she was doing wrong every time she played \"King and Queen.\" She knew the milk was not hers, but Mrs. Gray\\'s; still she said to herself, \"Ruthie needn\\'t give so much measure, all pressed down and run over. If Queenie and I should drink a great deal more, there would always be a quart left. Yes, I know there would.\"\\nMrs. Gray never said anything about the milk; she merely poured it out in a pan, and gave back the pail to Dotty, asking her at the same time as many questions as the child would stay to hear.',\r\n",
        "             'Cell division is the process by which a parent cell divides into two or more daughter cells. Cell division usually occurs as part of a larger cell cycle.\\n In eukaryotes, there are two distinct types of cell division: a vegetative division, whereby each daughter cell is genetically identical to the parent cell (mitosis), and a reproductive cell division, whereby the number of chromosomes in the daughter cells is reduced by half, to produce haploid gametes (meiosis). \\nMeiosis results in four haploid daughter cells by undergoing one round of DNA replication followed by two divisions: homologous chromosomes are separated in the first division, and sister chromatids are separated in the second division.\\nBoth of these cell division cycles are used in sexually reproducing organisms at some point in their life cycle, and both are believed to be present in the last eukaryotic common ancestor. Prokaryotes also undergo a vegetative cell division known as binary fission, where their genetic material is segregated equally into two daughter cells. All cell divisions, regardless of organism, are preceded by a single round of DNA replication.'],\r\n",
        "}\r\n",
        "\r\n",
        "body = str.encode(json.dumps(data))\r\n",
        "\r\n",
        "url = 'http://16705546-cea5-4e3e-99a7-6274ca5c4289.australiaeast.azurecontainer.io/score'\r\n",
        "api_key = '' # Replace this with the API key for the web service\r\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\r\n",
        "\r\n",
        "req = urllib.request.Request(url, body, headers)\r\n",
        "\r\n",
        "try:\r\n",
        "    response = urllib.request.urlopen(req)\r\n",
        "\r\n",
        "    result = response.read()\r\n",
        "    print(result)\r\n",
        "except urllib.error.HTTPError as error:\r\n",
        "    print(\"The request failed with status code: \" + str(error.code))\r\n",
        "\r\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\r\n",
        "    print(error.info())\r\n",
        "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'[-0.22421890497207642, -2.2895405292510986]'\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49E2NJ_W83wR",
        "outputId": "f42a4875-6925-4dd5-d14f-6bc91b09c936"
      }
    }
  ]
}