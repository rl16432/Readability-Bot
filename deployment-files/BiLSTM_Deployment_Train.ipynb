{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "CommonlitBidirectionalLSTM - Seed 3 Deployment ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.4 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "5eb756464d92b1fba7c316c219a9aedd64e50b1f9cf7b2745bd052621490d6a2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install azureml library"
      ],
      "metadata": {
        "id": "TTg8xWWuUtDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "! pip install azureml-core"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq157FQgnayO",
        "outputId": "aa9a14ba-afcc-4a74-d45c-f53b3ad2bd58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create workspace from Azure Machine Learning workspace"
      ],
      "metadata": {
        "id": "SP5cQLx9Uop7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "source_dir = \"./source_dir/\"\r\n",
        "\r\n",
        "ws = Workspace.from_config(path = source_dir + \"config.json\")\r\n",
        "print(ws)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-kDETxkozhl",
        "outputId": "c629a54d-e0e8-4ab7-e535-b4d9a478658c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Re-training LSTM model from Kaggle with same seed"
      ],
      "metadata": {
        "id": "XFkX6QZfUV6I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "import numpy as np # linear algebra\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "import random\r\n",
        "import os\r\n",
        "import io\r\n",
        "import json\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "metadata": {
        "id": "4jWYKx5vqI_O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "tf.random.set_seed(3)\r\n",
        "np.random.seed(3)\r\n",
        "random.seed(3)\r\n",
        "os.environ['PYTHONHASHSEED'] = '3'"
      ],
      "outputs": [],
      "metadata": {
        "id": "P2C9oZoNr4Xj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "train_eval_data = pd.read_csv(source_dir + \"data/train.csv\")\r\n",
        "pred_data = pd.read_csv(source_dir + \"data/test.csv\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "vCC1vnqLvKNW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "train_data, eval_data = train_test_split(train_eval_data, test_size = 0.2, random_state = 42)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4i550skmwndy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "train_text = train_data.loc[:,'excerpt'].values\r\n",
        "pred_text = pred_data.loc[:,'excerpt'].values\r\n",
        "eval_text = eval_data.loc[:,'excerpt'].values\r\n",
        "\r\n",
        "train_targets = train_data.loc[:,'target'].values\r\n",
        "eval_targets = eval_data.loc[:,'target'].values"
      ],
      "outputs": [],
      "metadata": {
        "id": "aOzUaDlbwqbi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer, text_to_word_sequence\r\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "tokenizer = Tokenizer()\r\n",
        "\r\n",
        "total_text = np.concatenate((train_text, eval_text, pred_text))\r\n",
        "All_text = np.array([text_to_word_sequence(s) for s in total_text], dtype = \"object\")\r\n",
        "\r\n",
        "tokenizer.fit_on_texts(All_text)\r\n",
        "\r\n",
        "max_length = max([len(s) for s in All_text])\r\n",
        "\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "\r\n",
        "train_text_tokens = tokenizer.texts_to_sequences(train_text)\r\n",
        "eval_text_tokens = tokenizer.texts_to_sequences(eval_text)\r\n",
        "pred_text_tokens = tokenizer.texts_to_sequences(pred_text)\r\n",
        "\r\n",
        "pad_train_tokens = pad_sequences(train_text_tokens, maxlen = max_length, padding = \"pre\")\r\n",
        "pad_eval_tokens = pad_sequences(eval_text_tokens, maxlen = max_length, padding = \"pre\")\r\n",
        "pad_pred_tokens = pad_sequences(pred_text_tokens, maxlen = max_length, padding = \"pre\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "V3s2SWuHw19v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import LSTM, Dense, Bidirectional\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.initializers import GlorotNormal\r\n",
        "from keras.losses import MeanSquaredError\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "EMBEDDING_SIZE = 90\r\n",
        "\r\n",
        "model.add(Embedding(vocab_size, EMBEDDING_SIZE, input_length = max_length, mask_zero = True,\r\n",
        "                    embeddings_initializer = GlorotNormal()))\r\n",
        "model.add(Bidirectional(LSTM(units = 128, dropout = 0.8)))\r\n",
        "model.add(Dense(activation=\"linear\", units = 1))\r\n",
        "\r\n",
        "model.compile(loss = MeanSquaredError(), optimizer = tf.keras.optimizers.Adam(\r\n",
        "              learning_rate=2e-4), metrics = ['mse'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "b-upXBOzw-x_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.fit(pad_train_tokens, train_targets, batch_size = 100, validation_data = (pad_eval_tokens, eval_targets), epochs = 10)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2pBA-z1qxISz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5479c83b-6c2a-466b-f45d-903fd34921e2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save pre-trained model"
      ],
      "metadata": {
        "id": "H9tqbbFhUeJc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.save(source_dir + 'models/Commonlit-Bi-LSTM')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./outputs/model2/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./outputs/model2/assets\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTLI0Q_Ft6HG",
        "outputId": "1eb8edc6-8255-4e5f-d68b-19c908eb1a34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save fitted Tokenizer for this model as tokenizer.json"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "tokenizer_json = tokenizer.to_json()\r\n",
        "with io.open(source_dir + 'models/Commonlit-Bi-LSTM/assets/tokenizer.json', 'w', encoding='utf-8') as f:\r\n",
        "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save max_length attribute which determines the necessary padding"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "with open(source_dir + 'models/Commonlit-Bi-LSTM/assets/max_length.txt', 'w') as text:\r\n",
        "    text.write(str(max_length))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test loading of pre-trained model"
      ],
      "metadata": {
        "id": "-WHHo-0TUiQU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "model_load = tf.keras.models.load_model(source_dir + 'models/Commonlit-Bi-LSTM')\r\n",
        "model_load.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 215, 90)           2581650   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 256)               224256    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 2,806,163\n",
            "Trainable params: 2,806,163\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUtLmcMWZhru",
        "outputId": "ccaa2938-0d2d-4a96-8428-e61c3c2b197b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make predictions and store in np.ndarray"
      ],
      "metadata": {
        "id": "iMV5IWD5Sizm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "test_preds = model_load.predict(x = pad_pred_tokens)\r\n",
        "test_preds"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.2834516 ],\n",
              "       [-0.22421896],\n",
              "       [-0.595436  ],\n",
              "       [-2.2895405 ],\n",
              "       [-1.713674  ],\n",
              "       [-0.2228559 ],\n",
              "       [-0.02093622]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC_DN6nHa1m_",
        "outputId": "2aab887c-0cae-40c2-fa35-45d4060b1e69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert test_preds to list of labels of type 'float'"
      ],
      "metadata": {
        "id": "Z_DtrU5pSpLe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "test_preds_list = test_preds.flatten().tolist()\r\n",
        "test_preds_list"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-1.2834515571594238,\n",
              " -0.2242189645767212,\n",
              " -0.5954359769821167,\n",
              " -2.2895405292510986,\n",
              " -1.7136739492416382,\n",
              " -0.22285589575767517,\n",
              " -0.02093621902167797]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "metadata": {
        "id": "7__KUQ5OI5Fe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register saved model on Azure"
      ],
      "metadata": {
        "id": "7miGRWMuS1yD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "# Register model\r\n",
        "model = Model.register(workspace = ws, \r\n",
        "                       model_name = \"Commonlit-Bi-LSTM\",\r\n",
        "                       model_path = source_dir + \"models/Commonlit-Bi-LSTM\",\r\n",
        "                       model_framework = \"TensorFlow\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering model Commonlit-BiLSTM-Seed3\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsvHpWvazEGE",
        "outputId": "8329301d-e2de-4085-ea21-f7688f1db05d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create environment with necessary dependencies"
      ],
      "metadata": {
        "id": "k8tvXAI7S8x4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "\r\n",
        "env = Environment(name = \"Commonlit-Bi-LSTM\")\r\n",
        "conda_dep = CondaDependencies()\r\n",
        "conda_dep.add_conda_package(\"numpy\")\r\n",
        "conda_dep.add_pip_package(\"keras\")\r\n",
        "conda_dep.add_pip_package(\"pandas\")\r\n",
        "\r\n",
        "conda_dep.add_pip_package('tensorflow==2.6.0')\r\n",
        "conda_dep.add_pip_package('sklearn')\r\n",
        "\r\n",
        "conda_dep.add_pip_package(\"azureml-defaults\")\r\n",
        "conda_dep.add_pip_package(\"azureml\")\r\n",
        "conda_dep.add_pip_package(\"azureml-contrib-functions\")\r\n",
        "\r\n",
        "env.python.conda_dependencies = conda_dep"
      ],
      "outputs": [],
      "metadata": {
        "id": "HLtc2V-Z0xpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create inference configuration using scoring function"
      ],
      "metadata": {
        "id": "-Bd1dvM7TAta"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "inference_config = InferenceConfig(\r\n",
        "    environment = env,\r\n",
        "    source_directory = \"./source_dir\",\r\n",
        "    entry_script = \"./Bi-LSTM_score_TRAIN.py\",\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "ndAkCFrC1bxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Azure Container Instance and deploy model to container"
      ],
      "metadata": {
        "id": "jeqyOZoSTGjh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.webservice import AciWebservice\r\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores = 2, memory_gb = 2)\r\n",
        "service = Model.deploy(\r\n",
        "    ws,\r\n",
        "    \"commonlit-bi-lstm\",\r\n",
        "    [model],\r\n",
        "    inference_config,\r\n",
        "    aci_config,\r\n",
        "    overwrite = True,\r\n",
        ")\r\n",
        "service.wait_for_deployment(show_output = True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2021-08-27 02:00:02+00:00 Creating Container Registry if not exists.\n",
            "2021-08-27 02:00:02+00:00 Registering the environment.\n",
            "2021-08-27 02:00:05+00:00 Use the existing image.\n",
            "2021-08-27 02:00:05+00:00 Generating deployment configuration.\n",
            "2021-08-27 02:00:06+00:00 Submitting deployment to compute..\n",
            "2021-08-27 02:00:10+00:00 Checking the status of deployment commonlit-bilstm-seed3..\n",
            "2021-08-27 02:04:53+00:00 Checking the status of inference endpoint commonlit-bilstm-seed3.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK7dPjJr2YT_",
        "outputId": "5ed5394b-57be-436e-ceaa-55e94b85cea6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Endpoint Consumption - Test 1"
      ],
      "metadata": {
        "id": "panzXiIKTMz0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import requests\r\n",
        "import json\r\n",
        "\r\n",
        "uri = service.scoring_uri\r\n",
        "requests.get(\"\") # Enter API here\r\n",
        "headers = {\"Content-Type\": \"application/json\"}\r\n",
        "data = {\r\n",
        "    'data': ['Cell division is the process by which a parent cell divides into two or more daughter cells. Cell division usually occurs as part of a larger cell cycle.\\n In eukaryotes, there are two distinct types of cell division: a vegetative division, whereby each daughter cell is genetically identical to the parent cell (mitosis), and a reproductive cell division, whereby the number of chromosomes in the daughter cells is reduced by half, to produce haploid gametes (meiosis). \\nMeiosis results in four haploid daughter cells by undergoing one round of DNA replication followed by two divisions: homologous chromosomes are separated in the first division, and sister chromatids are separated in the second division.\\nBoth of these cell division cycles are used in sexually reproducing organisms at some point in their life cycle, and both are believed to be present in the last eukaryotic common ancestor. Prokaryotes also undergo a vegetative cell division known as binary fission, where their genetic material is segregated equally into two daughter cells. All cell divisions, regardless of organism, are preceded by a single round of DNA replication.']\r\n",
        "}\r\n",
        "data = json.dumps(data)\r\n",
        "response = requests.post(uri, data = data, headers = headers)\r\n",
        "print(response.json())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.2895405292510986]\n"
          ]
        }
      ],
      "metadata": {
        "id": "iquzod856XeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56d44777-01d3-4ab5-b592-e0757ffbd7fd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Endpoint Consumption - Test 2"
      ],
      "metadata": {
        "id": "UN-EdJ4DTQdF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import urllib.request\r\n",
        "import json\r\n",
        "import os\r\n",
        "import ssl\r\n",
        "\r\n",
        "def allowSelfSignedHttps(allowed):\r\n",
        "    # bypass the server certificate verification on client side\r\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\r\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\r\n",
        "\r\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\r\n",
        "\r\n",
        "# Request data goes here\r\n",
        "data = {\r\n",
        "    'data': ['Dotty continued to go to Mrs. Gray\\'s every night with the milk. Sometimes Katie went with her, and then they always paused a while under the acorn-tree and played \"King and Queen.\" Dotty said she wished they could ever remember to bring their nipperkins, for in that case the milk would taste a great deal more like nectar. The \"nipperkins\" were a pair of handled cups which the children supposed to be silver, and which they always used at table.\\nDotty knew she was doing wrong every time she played \"King and Queen.\" She knew the milk was not hers, but Mrs. Gray\\'s; still she said to herself, \"Ruthie needn\\'t give so much measure, all pressed down and run over. If Queenie and I should drink a great deal more, there would always be a quart left. Yes, I know there would.\"\\nMrs. Gray never said anything about the milk; she merely poured it out in a pan, and gave back the pail to Dotty, asking her at the same time as many questions as the child would stay to hear.',\r\n",
        "             'Cell division is the process by which a parent cell divides into two or more daughter cells. Cell division usually occurs as part of a larger cell cycle.\\n In eukaryotes, there are two distinct types of cell division: a vegetative division, whereby each daughter cell is genetically identical to the parent cell (mitosis), and a reproductive cell division, whereby the number of chromosomes in the daughter cells is reduced by half, to produce haploid gametes (meiosis). \\nMeiosis results in four haploid daughter cells by undergoing one round of DNA replication followed by two divisions: homologous chromosomes are separated in the first division, and sister chromatids are separated in the second division.\\nBoth of these cell division cycles are used in sexually reproducing organisms at some point in their life cycle, and both are believed to be present in the last eukaryotic common ancestor. Prokaryotes also undergo a vegetative cell division known as binary fission, where their genetic material is segregated equally into two daughter cells. All cell divisions, regardless of organism, are preceded by a single round of DNA replication.'],\r\n",
        "}\r\n",
        "\r\n",
        "body = str.encode(json.dumps(data))\r\n",
        "\r\n",
        "url = ''\r\n",
        "api_key = '' # Replace this with the API key for the web service\r\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\r\n",
        "\r\n",
        "req = urllib.request.Request(url, body, headers)\r\n",
        "\r\n",
        "try:\r\n",
        "    response = urllib.request.urlopen(req)\r\n",
        "\r\n",
        "    result = response.read()\r\n",
        "    print(result)\r\n",
        "except urllib.error.HTTPError as error:\r\n",
        "    print(\"The request failed with status code: \" + str(error.code))\r\n",
        "\r\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\r\n",
        "    print(error.info())\r\n",
        "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'[-0.22421890497207642, -2.2895405292510986]'\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49E2NJ_W83wR",
        "outputId": "f42a4875-6925-4dd5-d14f-6bc91b09c936"
      }
    }
  ]
}