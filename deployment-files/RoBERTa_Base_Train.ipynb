{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":1,"source":["!pip install datasets"],"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n","\u001b[K     |████████████████████████████████| 264 kB 915 kB/s eta 0:00:01     |██████████████████████████      | 215 kB 915 kB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.0.1)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\n","Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2021.6.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.19.5)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (3.4.0)\n","Requirement already satisfied: huggingface-hub<0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.0.8)\n","Requirement already satisfied: tqdm>=4.42 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.61.1)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.25.1)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (20.9)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.2.4)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 8.5 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n","Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.5)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2021.5.30)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, datasets\n","Successfully installed datasets-1.11.0 xxhash-2.0.2\n","\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:26:41.902072Z","iopub.execute_input":"2021-08-29T05:26:41.902452Z","iopub.status.idle":"2021-08-29T05:26:50.966831Z","shell.execute_reply.started":"2021-08-29T05:26:41.902368Z","shell.execute_reply":"2021-08-29T05:26:50.965856Z"},"trusted":true}},{"cell_type":"markdown","source":["### Import libraries"],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["# This Python 3 environment comes with many helpful analytics libraries installed\r\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\r\n","# For example, here's several helpful packages to load\r\n","\r\n","import numpy as np # linear algebra\r\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n","import random\r\n","\r\n","import torch\r\n","\r\n","from datasets.arrow_dataset import Dataset\r\n","\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","from transformers import AutoTokenizer\r\n","from transformers import Trainer\r\n","from transformers import TrainingArguments\r\n","from transformers import AutoModelForSequenceClassification\r\n","\r\n","# Input data files are available in the read-only \"../input/\" directory\r\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\r\n","\r\n","import os\r\n","for dirname, _, filenames in os.walk('/kaggle/input'):\r\n","    for filename in filenames:\r\n","        print(os.path.join(dirname, filename))\r\n","\r\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \r\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"outputs":[{"output_type":"stream","name":"stdout","text":["/kaggle/input/commonlitreadabilityprize/sample_submission.csv\n","/kaggle/input/commonlitreadabilityprize/train.csv\n","/kaggle/input/commonlitreadabilityprize/test.csv\n"]}],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-29T05:26:50.970416Z","iopub.execute_input":"2021-08-29T05:26:50.970691Z","iopub.status.idle":"2021-08-29T05:26:58.213096Z","shell.execute_reply.started":"2021-08-29T05:26:50.970663Z","shell.execute_reply":"2021-08-29T05:26:58.212218Z"},"trusted":true}},{"cell_type":"markdown","source":["### Seed everything for reproducibility"],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["seed = 3\r\n","\r\n","# python RNG\r\n","random.seed(seed)\r\n","\r\n","# pytorch RNGs\r\n","torch.manual_seed(seed)\r\n","torch.backends.cudnn.deterministic = True\r\n","if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\r\n","\r\n","# numpy RNG\r\n","np.random.seed(seed)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:33:19.682300Z","iopub.execute_input":"2021-08-29T05:33:19.682679Z","iopub.status.idle":"2021-08-29T05:33:19.690074Z","shell.execute_reply.started":"2021-08-29T05:33:19.682626Z","shell.execute_reply":"2021-08-29T05:33:19.688953Z"},"trusted":true}},{"cell_type":"markdown","source":["### Load training and prediction data"],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["source_dir = '/kaggle/input/commonlitreadabilityprize/'\r\n","train_data = pd.read_csv(source_dir + 'train.csv')\r\n","train_data = train_data.drop(columns = [\"id\", \"url_legal\", \"license\", \"standard_error\"]).rename(columns = {\"target\": \"labels\"})\r\n","\r\n","preds_data = pd.read_csv(source_dir + 'test.csv')"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:33:23.750038Z","iopub.execute_input":"2021-08-29T05:33:23.750379Z","iopub.status.idle":"2021-08-29T05:33:23.801028Z","shell.execute_reply.started":"2021-08-29T05:33:23.750340Z","shell.execute_reply":"2021-08-29T05:33:23.800207Z"},"trusted":true}},{"cell_type":"markdown","source":["### Replace new line indicators with spaces to remove unnecessary tokens "],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["train_data['excerpt'] = train_data['excerpt'].apply(lambda x : x.replace('\\n', ' '))\r\n","preds_data['excerpt'] = preds_data['excerpt'].apply(lambda x : x.replace('\\n', ' '))"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:33:24.377972Z","iopub.execute_input":"2021-08-29T05:33:24.378304Z","iopub.status.idle":"2021-08-29T05:33:24.386941Z","shell.execute_reply.started":"2021-08-29T05:33:24.378274Z","shell.execute_reply":"2021-08-29T05:33:24.386073Z"},"trusted":true}},{"cell_type":"markdown","source":["### Split train.csv into training and validation sets to evaluate model training"],"metadata":{}},{"cell_type":"code","execution_count":10,"source":["train_set, eval_set = train_test_split(train_data, test_size = 0.2, random_state = 42)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:33:25.058012Z","iopub.execute_input":"2021-08-29T05:33:25.058386Z","iopub.status.idle":"2021-08-29T05:33:25.065481Z","shell.execute_reply.started":"2021-08-29T05:33:25.058338Z","shell.execute_reply":"2021-08-29T05:33:25.064469Z"},"trusted":true}},{"cell_type":"markdown","source":["### Convert pandas DataFrame to Dataset object\n","\n","This is done in order to map tokens into a class which is compatible with Huggingface model"],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["train_dataset = Dataset.from_pandas(df = train_set)\r\n","eval_dataset = Dataset.from_pandas(df = eval_set)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:33:25.498053Z","iopub.execute_input":"2021-08-29T05:33:25.498375Z","iopub.status.idle":"2021-08-29T05:33:25.526662Z","shell.execute_reply.started":"2021-08-29T05:33:25.498347Z","shell.execute_reply":"2021-08-29T05:33:25.525848Z"},"trusted":true}},{"cell_type":"markdown","source":["### Load pretrained RoBERTa tokenizer\n","\n","* Convert text into numerical form to pass into the transformer"],"metadata":{}},{"cell_type":"code","execution_count":12,"source":["tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\r\n","tokenizer.save_pretrained('./Commonlit-RoBERTa-Base/tokenizer')"],"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"803c8b11e2f6433ab9f0fbcb2faba72e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a60b5ff091a46d386f98975b5360666"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ba363e6c4284801835c28eb1a473cc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54311853cad248178b81ccc8cc90c2c0"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["('./Commonlit-RoBERTa-Base/tokenizer/tokenizer_config.json',\n"," './Commonlit-RoBERTa-Base/tokenizer/special_tokens_map.json',\n"," './Commonlit-RoBERTa-Base/tokenizer/vocab.json',\n"," './Commonlit-RoBERTa-Base/tokenizer/merges.txt',\n"," './Commonlit-RoBERTa-Base/tokenizer/added_tokens.json',\n"," './Commonlit-RoBERTa-Base/tokenizer/tokenizer.json')"]},"metadata":{},"execution_count":12}],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:33:25.978042Z","iopub.execute_input":"2021-08-29T05:33:25.978371Z","iopub.status.idle":"2021-08-29T05:33:31.345978Z","shell.execute_reply.started":"2021-08-29T05:33:25.978342Z","shell.execute_reply":"2021-08-29T05:33:31.345168Z"},"trusted":true}},{"cell_type":"code","execution_count":13,"source":["tokenizer"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["PreTrainedTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"]},"metadata":{},"execution_count":13}],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:33:31.347357Z","iopub.execute_input":"2021-08-29T05:33:31.347695Z","iopub.status.idle":"2021-08-29T05:33:31.353503Z","shell.execute_reply.started":"2021-08-29T05:33:31.347661Z","shell.execute_reply":"2021-08-29T05:33:31.352663Z"},"trusted":true}},{"cell_type":"markdown","source":["### Map tokenized text excerpts to Dataset"],"metadata":{}},{"cell_type":"code","execution_count":14,"source":["MAX_LENGTH = 256\r\n","\r\n","def tokenize_data(dataset):\r\n","    token_sequence = tokenizer(dataset[\"excerpt\"], padding = \"max_length\", truncation = True, max_length = MAX_LENGTH)\r\n","    return token_sequence\r\n","\r\n","# Map tokenized text (input_ids, attention_mask) to new dataset\r\n","tokenized_train_dataset = train_dataset.map(tokenize_data, batched = True).remove_columns([\"__index_level_0__\"])\r\n","tokenized_eval_dataset = eval_dataset.map(tokenize_data, batched = True).remove_columns([\"__index_level_0__\"])\r\n","\r\n","# Convert into PyTorch tensors\r\n","tokenized_train_dataset.set_format(\"torch\")\r\n","tokenized_eval_dataset.set_format(\"torch\")"],"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec735d34a99840c1a13636ab58890e2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fa1c30368e84b3c9112fc0430d5a46b"}},"metadata":{}}],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:33:31.355213Z","iopub.execute_input":"2021-08-29T05:33:31.355916Z","iopub.status.idle":"2021-08-29T05:33:33.249656Z","shell.execute_reply.started":"2021-08-29T05:33:31.355855Z","shell.execute_reply":"2021-08-29T05:33:33.248867Z"},"trusted":true}},{"cell_type":"code","execution_count":15,"source":["tokenized_train_dataset['input_ids']"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[    0,   133,   745,  ...,     1,     1,     1],\n","        [    0,   133,  1114,  ...,     1,     1,     1],\n","        [    0, 37818,     5,  ...,     1,     1,     1],\n","        ...,\n","        [    0,   100,  1017,  ...,  6063,  4864,     2],\n","        [    0,  1121,   209,  ...,     1,     1,     1],\n","        [    0, 39488,    16,  ...,     1,     1,     1]])"]},"metadata":{},"execution_count":15}],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:33:33.251254Z","iopub.execute_input":"2021-08-29T05:33:33.251603Z","iopub.status.idle":"2021-08-29T05:33:33.295090Z","shell.execute_reply.started":"2021-08-29T05:33:33.251568Z","shell.execute_reply":"2021-08-29T05:33:33.294118Z"},"trusted":true}},{"cell_type":"markdown","source":["### Load RoBERTa-Base model"],"metadata":{}},{"cell_type":"code","execution_count":16,"source":["# Load model from Huggingface\r\n","model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels = 1)"],"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5689752e889045b0bd24785f8fa07726"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:33:33.296497Z","iopub.execute_input":"2021-08-29T05:33:33.296862Z","iopub.status.idle":"2021-08-29T05:33:48.545872Z","shell.execute_reply.started":"2021-08-29T05:33:33.296827Z","shell.execute_reply":"2021-08-29T05:33:48.545085Z"},"trusted":true}},{"cell_type":"code","execution_count":17,"source":["%%capture\r\n","\r\n","# Send model to GPU\r\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n","model.to(device)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:33:48.547925Z","iopub.execute_input":"2021-08-29T05:33:48.548264Z","iopub.status.idle":"2021-08-29T05:33:54.582885Z","shell.execute_reply.started":"2021-08-29T05:33:48.548227Z","shell.execute_reply":"2021-08-29T05:33:54.582037Z"},"trusted":true}},{"cell_type":"markdown","source":["### Set up Trainer instance to train model"],"metadata":{}},{"cell_type":"code","execution_count":18,"source":["batch_size = 16\r\n","\r\n","training_args = TrainingArguments(\r\n","    output_dir=\"./Commonlit-RoBERTa-Base-CP\", # Select model path for checkpoint\r\n","    overwrite_output_dir=True,\r\n","    num_train_epochs=5,\r\n","    per_device_train_batch_size = batch_size,\r\n","    per_device_eval_batch_size = batch_size,\r\n","    evaluation_strategy = 'epoch',\r\n","    save_strategy = \"epoch\", # Save checkpoint at end of each epoch\r\n","    metric_for_best_model = 'eval_loss',\r\n","    greater_is_better = False,\r\n","    load_best_model_at_end = True,\r\n","    report_to = \"none\",\r\n","    seed = 3)\r\n","\r\n","trainer = Trainer(\r\n","    model = model,\r\n","    args = training_args,\r\n","    train_dataset = tokenized_train_dataset,\r\n","    eval_dataset = tokenized_eval_dataset)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:33:54.584462Z","iopub.execute_input":"2021-08-29T05:33:54.584785Z","iopub.status.idle":"2021-08-29T05:33:54.975411Z","shell.execute_reply.started":"2021-08-29T05:33:54.584750Z","shell.execute_reply":"2021-08-29T05:33:54.974559Z"},"trusted":true}},{"cell_type":"code","execution_count":19,"source":["trainer.train()"],"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='710' max='710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [710/710 07:17, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.408047</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.544274</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.444234</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.296400</td>\n","      <td>0.277034</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.296400</td>\n","      <td>0.333592</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=710, training_loss=0.22970777431004483, metrics={'train_runtime': 438.708, 'train_samples_per_second': 1.618, 'total_flos': 0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 604647424, 'train_mem_gpu_alloc_delta': 1562336768, 'train_mem_cpu_peaked_delta': 4280320, 'train_mem_gpu_peaked_delta': 4541207552})"]},"metadata":{},"execution_count":19}],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:33:54.976625Z","iopub.execute_input":"2021-08-29T05:33:54.976971Z","iopub.status.idle":"2021-08-29T05:41:14.275953Z","shell.execute_reply.started":"2021-08-29T05:33:54.976938Z","shell.execute_reply":"2021-08-29T05:41:14.275074Z"},"trusted":true}},{"cell_type":"code","execution_count":20,"source":["%%capture\r\n","# Convert model to evaluation mode to indicate model is ready for prediction\r\n","model.eval()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:41:14.277251Z","iopub.execute_input":"2021-08-29T05:41:14.277607Z","iopub.status.idle":"2021-08-29T05:41:14.287518Z","shell.execute_reply.started":"2021-08-29T05:41:14.277573Z","shell.execute_reply":"2021-08-29T05:41:14.286548Z"},"trusted":true}},{"cell_type":"markdown","source":["### Save pre-trained model"],"metadata":{}},{"cell_type":"code","execution_count":21,"source":["trainer.save_model('./Commonlit-RoBERTa-Base')"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:41:14.288947Z","iopub.execute_input":"2021-08-29T05:41:14.289275Z","iopub.status.idle":"2021-08-29T05:41:16.420488Z","shell.execute_reply.started":"2021-08-29T05:41:14.289242Z","shell.execute_reply":"2021-08-29T05:41:16.419438Z"},"trusted":true}},{"cell_type":"markdown","source":["### Make predictions"],"metadata":{}},{"cell_type":"code","execution_count":22,"source":["preds_targets = []\r\n","\r\n","for excerpt in preds_data['excerpt']:\r\n","    token_seq = tokenizer(excerpt, padding = \"max_length\", max_length = MAX_LENGTH, truncation = True, return_tensors = \"pt\")\r\n","    token_seq.to(device)\r\n","    pred = model(**token_seq) # Unpack token sequences tensor \r\n","    preds_targets.append(pred.logits[0].item())\r\n","    \r\n","preds_targets"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[-0.007161587942391634,\n"," -0.3461619019508362,\n"," -0.18076074123382568,\n"," -2.6938998699188232,\n"," -1.7281757593154907,\n"," -0.8599075675010681,\n"," 0.5470359325408936]"]},"metadata":{},"execution_count":22}],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:41:16.422085Z","iopub.execute_input":"2021-08-29T05:41:16.422439Z","iopub.status.idle":"2021-08-29T05:41:16.781640Z","shell.execute_reply.started":"2021-08-29T05:41:16.422405Z","shell.execute_reply":"2021-08-29T05:41:16.780826Z"},"trusted":true}},{"cell_type":"code","execution_count":23,"source":["submission_df = pd.DataFrame({'id' : preds_data['id'], 'target': preds_targets})"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:41:16.782934Z","iopub.execute_input":"2021-08-29T05:41:16.783247Z","iopub.status.idle":"2021-08-29T05:41:17.258916Z","shell.execute_reply.started":"2021-08-29T05:41:16.783213Z","shell.execute_reply":"2021-08-29T05:41:17.257892Z"},"trusted":true}},{"cell_type":"code","execution_count":24,"source":["submission_df.to_csv(\"submission.csv\", index = False)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:41:17.260442Z","iopub.execute_input":"2021-08-29T05:41:17.260820Z","iopub.status.idle":"2021-08-29T05:41:17.270703Z","shell.execute_reply.started":"2021-08-29T05:41:17.260782Z","shell.execute_reply":"2021-08-29T05:41:17.269877Z"},"trusted":true}}]}